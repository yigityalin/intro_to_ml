{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaea8aa",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedbd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9b9ea",
   "metadata": {},
   "source": [
    "# Question 1: The CS 464 Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b8145",
   "metadata": {},
   "source": [
    "## Enumerate the study habits and grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bee0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyHabits(IntEnum):\n",
    "    MOTIVATED = 0\n",
    "    UNMOTIVATED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cde79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grades(IntEnum):\n",
    "    HIGH = 0\n",
    "    LOW = 1\n",
    "    FAILING = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b2656",
   "metadata": {},
   "source": [
    "## Construct the probability matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24592975",
   "metadata": {},
   "source": [
    "0.87 of the high grades are received by the motivated students.\n",
    "0.21 of the low grades are received by the motivated students.\n",
    "0.04 of the failing grades are received by the motivated students.\n",
    "\n",
    "These imply that\n",
    "0.13 of the high grades are received by the unmotivated students.\n",
    "0.79 of the low grades are received by the unmotivated students.\n",
    "0.96 of the failing grades are received by the unmotivated students.\n",
    "\n",
    "Multiplying these with the following probabilities will give us the ratios of all the probabilities.\n",
    "\n",
    "$$P(H) = 0.64$$\n",
    "$$P(L) = 0.21$$\n",
    "$$P(F) = 0.04$$\n",
    "\n",
    "The calculations can be seen on the following cell. The rows represent the grades and the columns represent the motivation of the student.\n",
    "\n",
    "Notice that the sum of elements in the same row give $P(H)$, $P(L)$, $P(F)$, respectively.\n",
    "\n",
    "The individual probabilities are obtained from the matrix with as following:\n",
    "\n",
    "P[The grade (H, L or F)][The motivation of the student (Motivated or Unmotivated)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bfcf1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5568, 0.0832],\n",
       "       [0.0504, 0.1896],\n",
       "       [0.0048, 0.1152]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.empty(shape=(len(Grades), len(StudyHabits)))\n",
    "\n",
    "P[Grades.HIGH, StudyHabits.MOTIVATED] = 0.87\n",
    "P[Grades.LOW, StudyHabits.MOTIVATED] = 0.21\n",
    "P[Grades.FAILING, StudyHabits.MOTIVATED] = 0.04\n",
    "\n",
    "P[..., StudyHabits.UNMOTIVATED] = 1 - P[..., StudyHabits.MOTIVATED]\n",
    "    \n",
    "P[Grades.HIGH] *= 0.64\n",
    "P[Grades.LOW] *= 0.24\n",
    "P[Grades.FAILING] *= 0.12\n",
    "\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0fdde",
   "metadata": {},
   "source": [
    "## Question 1.1: What is the probability that a student is motivated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae09275",
   "metadata": {},
   "source": [
    "$P(S_M)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdf5c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.612"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[..., StudyHabits.MOTIVATED].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea34d4",
   "metadata": {},
   "source": [
    "## Question 1.2: If a student is motivated, what is the probability that he/she will get a high grade?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02d94a",
   "metadata": {},
   "source": [
    "$P(H|S_M) = \\dfrac{P(H, S_M)}{P(S_M)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ea7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098039215686274"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[Grades.HIGH, StudyHabits.MOTIVATED] / P[..., StudyHabits.MOTIVATED].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29033c57",
   "metadata": {},
   "source": [
    "## Question 1.3: If a student is unmotivated, what is the probability that he/she will get a high grade?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd9d4b",
   "metadata": {},
   "source": [
    "$P(H|S_U) = \\dfrac{P(H, S_U)}{P(S_U)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998b2628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21443298969072166"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[Grades.HIGH, StudyHabits.UNMOTIVATED] / P[..., StudyHabits.UNMOTIVATED].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9f3b4",
   "metadata": {},
   "source": [
    "# Question 2: Sports News Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a50512",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = Path().resolve()\n",
    "DATA_PATH = PROJECT_ROOT_DIR / 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66d94eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbcsports_val.csv', 'bbcsports_train.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[file.name for file in DATA_PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24b6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = DATA_PATH / 'bbcsports_train.csv'\n",
    "VALID_DATA_PATH = DATA_PATH / 'bbcsports_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f886fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "data_valid = pd.read_csv(VALID_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27da0b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claxton</th>\n",
       "      <th>hunt</th>\n",
       "      <th>first</th>\n",
       "      <th>major</th>\n",
       "      <th>medal</th>\n",
       "      <th>british</th>\n",
       "      <th>hurdler</th>\n",
       "      <th>sarah</th>\n",
       "      <th>confid</th>\n",
       "      <th>win</th>\n",
       "      <th>...</th>\n",
       "      <th>massu</th>\n",
       "      <th>mcenro</th>\n",
       "      <th>mauresmo</th>\n",
       "      <th>ameli</th>\n",
       "      <th>hip</th>\n",
       "      <th>fiveset</th>\n",
       "      <th>mario</th>\n",
       "      <th>ancic</th>\n",
       "      <th>lundgren</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claxton  hunt  first  major  medal  british  hurdler  sarah  confid  win  \\\n",
       "0        0     0      0      0      0        0        0      0       0    0   \n",
       "1        0     0      1      0      0        0        0      0       0    1   \n",
       "2        0     0      1      0      0        0        0      0       0    2   \n",
       "3        0     0      0      2      0        0        0      0       0    0   \n",
       "4        0     0      0      0      0        0        0      0       0    1   \n",
       "\n",
       "   ...  massu  mcenro  mauresmo  ameli  hip  fiveset  mario  ancic  lundgren  \\\n",
       "0  ...      0       0         0      0    0        0      0      0         0   \n",
       "1  ...      0       0         0      0    0        0      0      0         0   \n",
       "2  ...      0       0         0      0    0        0      0      0         0   \n",
       "3  ...      0       0         0      0    0        0      0      0         0   \n",
       "4  ...      0       0         0      0    0        0      0      0         0   \n",
       "\n",
       "   class_label  \n",
       "0            3  \n",
       "1            1  \n",
       "2            2  \n",
       "3            2  \n",
       "4            2  \n",
       "\n",
       "[5 rows x 4614 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee121c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claxton</th>\n",
       "      <th>hunt</th>\n",
       "      <th>first</th>\n",
       "      <th>major</th>\n",
       "      <th>medal</th>\n",
       "      <th>british</th>\n",
       "      <th>hurdler</th>\n",
       "      <th>sarah</th>\n",
       "      <th>confid</th>\n",
       "      <th>win</th>\n",
       "      <th>...</th>\n",
       "      <th>massu</th>\n",
       "      <th>mcenro</th>\n",
       "      <th>mauresmo</th>\n",
       "      <th>ameli</th>\n",
       "      <th>hip</th>\n",
       "      <th>fiveset</th>\n",
       "      <th>mario</th>\n",
       "      <th>ancic</th>\n",
       "      <th>lundgren</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claxton  hunt  first  major  medal  british  hurdler  sarah  confid  win  \\\n",
       "0        0     0      0      0      0        0        0      0       0    0   \n",
       "1        0     0      0      0      0        0        0      0       0    0   \n",
       "2        0     0      8      1      0        0        0      0       0    0   \n",
       "3        0     0      0      0      0        0        0      0       0    0   \n",
       "4        0     0      1      0      0        0        0      0       0    0   \n",
       "\n",
       "   ...  massu  mcenro  mauresmo  ameli  hip  fiveset  mario  ancic  lundgren  \\\n",
       "0  ...      0       0         0      0    0        0      0      0         0   \n",
       "1  ...      0       0         0      0    0        0      0      0         0   \n",
       "2  ...      0       0         0      0    0        0      0      0         0   \n",
       "3  ...      0       0         0      0    0        0      0      0         0   \n",
       "4  ...      0       0         0      0    0        0      0      0         0   \n",
       "\n",
       "   class_label  \n",
       "0            4  \n",
       "1            2  \n",
       "2            1  \n",
       "3            2  \n",
       "4            4  \n",
       "\n",
       "[5 rows x 4614 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1661ffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 185)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train), len(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024cd72",
   "metadata": {},
   "source": [
    "## Question 2.1.1: How are the classes distributed in the training set? Give the number of instances in each class with a suitable plot. Any plot that shows the class distribution is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58fc93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_label\n",
       "2              198\n",
       "3              114\n",
       "1               86\n",
       "0               77\n",
       "4               77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[['class_label']].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07143416",
   "metadata": {},
   "source": [
    "We can see that the number of instances that belong to the second class approximately twice of the number of instances for each of the other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a0e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train[['class_label']].value_counts(sort=False).plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(ticks=list(range(5)), labels=list(range(5)))\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of instances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38464377",
   "metadata": {},
   "source": [
    "## Question 2.1.2: Is the training set balanced or skewed towards one of the classes? Do you think having an imbalanced training set affects your model? If yes, please explain how it affects the Naive Bayes model and propose a possible solution if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96fc25",
   "metadata": {},
   "source": [
    "The training set is imbalanced though the imbalance is not extreme. The class 2 is dominant in the training set, and this causes bias in the weights of the Naive Bayes classifier. If the imbalanced class distribution in the training set does not match with the true class distribution, the priors $P(Y = y_k)$ will be misleading, that is the probability of the minority class will be very small because of the imbalance. In these cases, ignoring the prior might give better results.\n",
    "\n",
    "In addition, if the number of training examples are not sufficient, the likelihoods can also be misleading. There might be no samples that represent a feature for a class, and thus, the model will give zero probability to new samples with that feature being in that class. In these cases, techniques like Laplace smoothing might prove useful to give a small probability (instead of zero) of a sample being in the underrepresented class.\n",
    "\n",
    "Though imbalanced dataset does usually reduce the model performance, it is still possible that the model might perform on the true distribution of the data (assuming that the dataset represents the true distribution). Therefore, training the model without dealing with the imbalance and checking whether the model generalized well is an option.\n",
    "\n",
    "If it does not generalize well on the true distribution of the data, upsampling the minority class and downsampling the majority class are two options. These techniques reduces the difference of the proportions of the data between the classes, thereby diminishing the imbalance problem. Another option is to synthesize new samples for minority class. These techniques might require additional adjustments to the algorithm. For example, for downsampling method, it might be useful to upweight the downsampled class, that is to put more importance on the samples of downsampled class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577bf6b1",
   "metadata": {},
   "source": [
    "## Question 2.1.3: Does the validation set, and the training set have similar data distributions? Regardless of the answer, if we had a bad split where validation set and the training set have different characteristics, which term in the Naive Bayes algorithm would be misleading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54213cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Set</th>\n",
       "      <th>Validation Set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139493</td>\n",
       "      <td>0.129730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155797</td>\n",
       "      <td>0.205405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.362162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.178378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139493</td>\n",
       "      <td>0.124324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train Set  Validation Set\n",
       "class_label                           \n",
       "0             0.139493        0.129730\n",
       "1             0.155797        0.205405\n",
       "2             0.358696        0.362162\n",
       "3             0.206522        0.178378\n",
       "4             0.139493        0.124324"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist = data_train[['class_label']].value_counts(sort=False) / len(data_train)\n",
    "test_dist = data_valid[['class_label']].value_counts(sort=False) / len(data_valid)\n",
    "\n",
    "dist = pd.concat([train_dist, test_dist], axis=1).rename({0: 'Train Set', 1: 'Validation Set'}, axis=1)\n",
    "\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "267c8e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist.plot(kind='bar')\n",
    "plt.title('Class Distributions in Train and Validation Sets')\n",
    "plt.xticks(ticks=list(range(5)), labels=list(range(5)))\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of instances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b57f9",
   "metadata": {},
   "source": [
    "We can see that the class distributions of train and validation sets are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcb35f",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier uses the proportion of each class $P(Y = y_k)$ for the predictions. If the class distributions of train and validation sets are not similar, this will mislead the classifier since the train dataset does not represent the true class distribution as it is corrupted during the split of the dataset.\n",
    "\n",
    "Also, if the number of training examples are not sufficient, the likelihoods can also be misleading as mentioned in the previous question. Some output probabilities of the model might be zero because of the training samples does not contain a class with one (or more) of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbf607",
   "metadata": {},
   "source": [
    "## Question 2.1.4: If your dataset is skewed towards one of the classes, does this affect your reported accuracy? If yes, to what extent the reported accuracy is misleading in such an unbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc33fdb",
   "metadata": {},
   "source": [
    "Though the accuracy metric is easy-to-interpret, it is not well-suited to assess the model performance on imbalanced datasets. For example, if the distribution of the data is 99%-1%, a model that predicts the majority class all the time achieves 99% accuracy. However, this model is not useful since it cannot correctly classify any examples from the minority class. Thus, accuracy is not a good metric for imbalanced classification tasks. Metrics like F1-score and F2-score (F-$\\beta$ score in general) are better for these tasks since take the class imbalance into the account while evaluating the results. Plotting the confusion matrix might also be useful for imbalanced classification tasks to see how the model works on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31388e00",
   "metadata": {},
   "source": [
    "## Create the Naive Bayes Classifier class for Question 2.2 and Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1fad7",
   "metadata": {},
   "source": [
    "**This base class implements all the basic functionality of the Naive Bayes classifier.**\n",
    "\n",
    "**For estimator = \"mle\", the classifier calculates maximum likelihood estimates (for Question 2).**\n",
    "\n",
    "**For estimator = \"map\", the classifier calculates maximum a posteriori estimates (for Question 3). Though the question only wants the $\\alpha = 1$ case, the following class implementation supports any $\\alpha > 0$**\n",
    "\n",
    "**Note that the only difference is the calculation of the likelihood. MAP estimation requires the addition of a some constant $\\alpha$ to the number of occurences, whereas MLE does not have this addition of a constant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612ffab",
   "metadata": {},
   "source": [
    "**calculate_pi function calculates the probabilities that any particular document belongs to the class $y_k \\: \\forall k\\in\\{0, 1, 2, 3, 4\\}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b997b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pi(data, label='class_label'):\n",
    "    probs = data[[label]].value_counts(sort=False) / len(data)\n",
    "    return np.log(probs.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aff528",
   "metadata": {},
   "source": [
    "**calculate_theta function calculates the likelihoods for MLE if $\\alpha = 0$ and for MAP if $\\alpha > 0$.**\n",
    "\n",
    "**The $-\\infty$ values are converted to a very small number for calculations by using np.nan_to_num function. The following cells illustrates how the function behaves for $-\\infty$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "509b2c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7976931348623157e+308"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(-np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ba2eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_theta(data, label='class_label', alpha=0):\n",
    "    class_word_counts = data.groupby(by=label).sum() + alpha\n",
    "    total_word_counts = class_word_counts.sum(axis=1)\n",
    "    probs = class_word_counts.T / total_word_counts\n",
    "    with np.errstate(divide='ignore'):\n",
    "        logprobs = np.log(np.asarray(probs))\n",
    "    logprobs = np.nan_to_num(logprobs)\n",
    "    return logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7f80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, estimator, alpha=None):\n",
    "        estimator = estimator.lower()\n",
    "\n",
    "        self._pi = None\n",
    "        self._theta = None\n",
    "        if estimator != 'mle' and estimator != 'map':\n",
    "            raise ValueError('Only MLE and MAP are supported.')\n",
    "        if estimator == 'map':\n",
    "            if alpha is None:\n",
    "                raise ValueError('You have to specify alpha if the estimator is MAP.')\n",
    "            elif alpha < 0:\n",
    "                raise ValueError('alpha must be larger than 0.')\n",
    "        self.estimator = estimator\n",
    "        self.alpha = alpha if estimator == 'map' else 0\n",
    "    \n",
    "    @property\n",
    "    def pi(self):\n",
    "        return self._pi\n",
    "    \n",
    "    @property\n",
    "    def theta(self):\n",
    "        return self._theta\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.estimator == 'mle':\n",
    "            return f'NaiveBayesClassifier(estimator={self.estimator})'\n",
    "        elif self.estimator == 'map':\n",
    "            return f'NaiveBayesClassifier(estimator={self.estimator}, alpha={self.alpha})'\n",
    "        else:\n",
    "            return NotImplementedError()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def fit(self, data, label='class_label'):\n",
    "        self._pi = calculate_pi(data, label)\n",
    "        self._theta = calculate_theta(data, label, alpha=self.alpha)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data, label='class_label'):\n",
    "        scores = np.asarray(self.get_scores(data, label))\n",
    "        return scores.argmax(axis=1)\n",
    "        \n",
    "    def get_scores(self, data, label='class_label'):\n",
    "        if self.pi is None or self.theta is None:\n",
    "            raise RuntimeError('The model is not fit.')\n",
    "        return self.pi + data.drop(label, axis=1) @ self.theta\n",
    "    \n",
    "    def evaluate(self, data, label='class_label'):\n",
    "        preds = self.predict(data, label)\n",
    "        labels = data[label]\n",
    "        return np.mean(preds == labels)\n",
    "    \n",
    "    def confusion_matrix(self, data, label='class_label'):\n",
    "        labels = data[label]\n",
    "        n_classes = labels.nunique()\n",
    "        preds = self.predict(data, label)\n",
    "        \n",
    "        cm = np.zeros(shape=(n_classes, n_classes))\n",
    "        for true, pred in zip(labels, preds):\n",
    "            cm[true][pred] += 1\n",
    "        \n",
    "        return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d83bad",
   "metadata": {},
   "source": [
    "## Question 2.2: Train a Multinomial Naive Bayes model on the training set and evaluate your model on the validation set given. Find and report the accuracy and the confusion matrix for the validation set, as well as how many wrong predictions were made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ecef0",
   "metadata": {},
   "source": [
    "### Create a Naive Bayes classifier that uses maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "238e0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mle = NaiveBayesClassifier(estimator='mle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdb92b",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9d7cbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveBayesClassifier(estimator=mle)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mle.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cef138",
   "metadata": {},
   "source": [
    "### Predict the classes for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a4fd250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 4, 0, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred_mle = nb_mle.predict(data_valid)\n",
    "valid_pred_mle[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bdbec",
   "metadata": {},
   "source": [
    "### Evaluate the model by calculating prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ec8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31351351351351353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mle.evaluate(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13467ad4",
   "metadata": {},
   "source": [
    "### Create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3bcfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.,  0.,  0.,  0.,  0.],\n",
       "       [33.,  5.,  0.,  0.,  0.],\n",
       "       [45.,  0., 22.,  0.,  0.],\n",
       "       [30.,  0.,  0.,  3.,  0.],\n",
       "       [19.,  0.,  0.,  0.,  4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mle.confusion_matrix(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd050f37",
   "metadata": {},
   "source": [
    "**The low accuracy of this model is because of the zeros in the training set. When the model encounters a sample with a word W that it has not previously seen for a class C, the model gives zero probability to the case that the sample belongs to the class C. However, this might not be the case. Since there are many zero entries in the feature dataset, the model gives zero probability to those samples belonging to a class. Thus, many of the classes are misclassified as class 0 as the classifies the lower class in order in the case of a tie. This is also explained in Question 2.4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7257def",
   "metadata": {},
   "source": [
    "## Question 2.3: Extend your classifier so that it can compute a MAP estimate of θ parameters using a fair Dirichlet prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35155a68",
   "metadata": {},
   "source": [
    "### Create a Naive Bayes classifier that uses maximum a posteriori estimator using a Dirichlet prior with $\\alpha = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61398750",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_map = NaiveBayesClassifier(estimator='map', alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202c0ba",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03970a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveBayesClassifier(estimator=map, alpha=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2a3c2",
   "metadata": {},
   "source": [
    "### Predict the classes for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc777ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1, 2, 4, 0, 0, 1, 2, 2, 1, 3, 3, 1, 0, 3, 1, 2, 3, 3, 3, 1,\n",
       "       2, 1, 3, 2, 3, 4, 3, 2, 3, 2, 1, 1, 3, 2, 2, 1, 2, 1, 2, 0, 1, 4,\n",
       "       3, 4, 4, 4, 2, 2, 2, 4, 2, 4, 0, 1, 0, 1, 2, 4, 0, 0, 2, 0, 3, 2,\n",
       "       1, 0, 2, 3, 0, 4, 0, 0, 3, 1, 2, 2, 4, 2, 2, 2, 2, 2, 3, 4, 2, 2,\n",
       "       4, 0, 2, 0, 2, 4, 3, 2, 1, 1, 0, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 3,\n",
       "       2, 1, 4, 0, 3, 2, 2, 3, 2, 2, 1, 3, 0, 1, 2, 3, 2, 3, 1, 1, 4, 2,\n",
       "       1, 3, 4, 3, 1, 2, 2, 3, 2, 3, 2, 2, 4, 3, 0, 2, 3, 4, 3, 3, 3, 2,\n",
       "       1, 2, 0, 2, 2, 2, 0, 3, 2, 2, 3, 2, 2, 1, 2, 0, 3, 1, 1, 2, 0, 0,\n",
       "       4, 2, 2, 3, 2, 0, 4, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map.predict(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05337b8b",
   "metadata": {},
   "source": [
    "### Evaluate the model by calculating prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e98c0591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972972972972973"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map.evaluate(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa841b",
   "metadata": {},
   "source": [
    "### Create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2131aa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.,  0.,  0.,  0.,  0.],\n",
       "       [ 0., 35.,  1.,  2.,  0.],\n",
       "       [ 0.,  0., 66.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., 33.,  0.],\n",
       "       [ 1.,  0.,  0.,  0., 22.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map.confusion_matrix(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86881f",
   "metadata": {},
   "source": [
    "## Question 2.4: Comparing the two models you trained, how does the Dirichlet prior α effects your model? Also, interpret the structure of the dataset. Given that the dataset does not include stop words, why are the two models different? Explain by giving references to your results. You can also benefit from the statistical structure of the feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c63d5",
   "metadata": {},
   "source": [
    "For clarity, let $\\alpha$ denote a word and $\\psi$ denote a class. When the Diriclet prior is not used, it might be the case that there is no samples from class $\\psi$ that contains the word $\\alpha$. Then, if there is a new sample which contains the word $\\alpha$, the model will output zero for that sample being in the class $\\psi$. By adding the prior, we prevent the model output to be zero. The outputs become small numbers instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f8456",
   "metadata": {},
   "source": [
    "For example, the confusion matrix for the MLE estimation (without the prior) shows that most of the samples are misclassified as class 0 since we predict the class that is lower in order in the case of ties.\n",
    "\n",
    "In the following cell, we see that there are many zero entries for each feature. This causes many of the outputs of the model to be zero when the model encounters new samples with that word. This causes ties and the model misclassifies the examples as class 0 as it is the class that is lower in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77953772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 0, 0, 2, 1, 4, 4, 0, 0, 0, 0, 2, 0, 3, 1, 1, 0, 4, 3, 0, 0,\n",
       "       0, 0, 3, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 0, 0, 3, 2, 4, 0, 1, 2, 4, 3, 0, 0, 0, 0, 1, 0,\n",
       "       2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 2, 0, 3, 0, 4, 2, 1, 0, 0,\n",
       "       2, 1, 1, 4, 3, 0, 0, 1, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(data_train.groupby('class_label').sum() == 0, 1, 0).sum(axis=0)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90156f7",
   "metadata": {},
   "source": [
    "The following cell shows the output of the model on the validation dataset. We see that there are many $-\\infty$ values. For many samples, all the probabilites are $-\\infty$, and thus, the model misclassifies the samples as class 0 (the class that is lower in order.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e61daeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-1.797693e+308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3              4\n",
       "0   -inf -inf -inf -inf           -inf\n",
       "1   -inf -inf -inf -inf           -inf\n",
       "2   -inf -inf -inf -inf           -inf\n",
       "3   -inf -inf -inf -inf           -inf\n",
       "4   -inf -inf -inf -inf -1.797693e+308\n",
       "..   ...  ...  ...  ...            ...\n",
       "180 -inf -inf -inf -inf           -inf\n",
       "181 -inf -inf -inf -inf           -inf\n",
       "182 -inf -inf -inf -inf           -inf\n",
       "183 -inf -inf -inf -inf           -inf\n",
       "184 -inf -inf -inf -inf           -inf\n",
       "\n",
       "[185 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mle.get_scores(data_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e3ca7",
   "metadata": {},
   "source": [
    "In the following cell, we can observe the effect of the prior $\\alpha$. There are no $-\\infty$ values since there is no zeros in the likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3739a24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1233.060177</td>\n",
       "      <td>-1231.921015</td>\n",
       "      <td>-1230.522389</td>\n",
       "      <td>-1235.827373</td>\n",
       "      <td>-1047.088547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1181.419956</td>\n",
       "      <td>-1169.898431</td>\n",
       "      <td>-1068.447380</td>\n",
       "      <td>-1151.796023</td>\n",
       "      <td>-1145.649153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7657.717286</td>\n",
       "      <td>-6557.608205</td>\n",
       "      <td>-7639.532552</td>\n",
       "      <td>-7615.212454</td>\n",
       "      <td>-7564.218066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1162.495946</td>\n",
       "      <td>-1178.713996</td>\n",
       "      <td>-1089.896843</td>\n",
       "      <td>-1164.804730</td>\n",
       "      <td>-1194.167169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1032.608840</td>\n",
       "      <td>-1050.741549</td>\n",
       "      <td>-1026.161416</td>\n",
       "      <td>-1041.338716</td>\n",
       "      <td>-891.342299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-2179.998139</td>\n",
       "      <td>-2152.516462</td>\n",
       "      <td>-1888.579209</td>\n",
       "      <td>-2145.308897</td>\n",
       "      <td>-2127.739230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-3078.034078</td>\n",
       "      <td>-3748.081551</td>\n",
       "      <td>-3675.843914</td>\n",
       "      <td>-3689.441685</td>\n",
       "      <td>-3512.934664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-848.301695</td>\n",
       "      <td>-835.398349</td>\n",
       "      <td>-841.306372</td>\n",
       "      <td>-830.082663</td>\n",
       "      <td>-757.861411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1751.711495</td>\n",
       "      <td>-1788.459220</td>\n",
       "      <td>-1502.930022</td>\n",
       "      <td>-1731.814688</td>\n",
       "      <td>-1744.487264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1445.443172</td>\n",
       "      <td>-1427.415390</td>\n",
       "      <td>-1323.582866</td>\n",
       "      <td>-1392.417878</td>\n",
       "      <td>-1426.071402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2            3            4\n",
       "0   -1233.060177 -1231.921015 -1230.522389 -1235.827373 -1047.088547\n",
       "1   -1181.419956 -1169.898431 -1068.447380 -1151.796023 -1145.649153\n",
       "2   -7657.717286 -6557.608205 -7639.532552 -7615.212454 -7564.218066\n",
       "3   -1162.495946 -1178.713996 -1089.896843 -1164.804730 -1194.167169\n",
       "4   -1032.608840 -1050.741549 -1026.161416 -1041.338716  -891.342299\n",
       "..           ...          ...          ...          ...          ...\n",
       "180 -2179.998139 -2152.516462 -1888.579209 -2145.308897 -2127.739230\n",
       "181 -3078.034078 -3748.081551 -3675.843914 -3689.441685 -3512.934664\n",
       "182  -848.301695  -835.398349  -841.306372  -830.082663  -757.861411\n",
       "183 -1751.711495 -1788.459220 -1502.930022 -1731.814688 -1744.487264\n",
       "184 -1445.443172 -1427.415390 -1323.582866 -1392.417878 -1426.071402\n",
       "\n",
       "[185 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map.get_scores(data_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
